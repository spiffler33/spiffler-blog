---
title: The AI Bubble That Isn't..
date: 2026-01-24
---

WHY MSFT, GOOG, AND AMZN ARE BETTER POSITIONED THAN THE NARRATIVE SUGGESTS


The AI bubble discourse has reached fever pitch. Capacity built but unused. Copilot adoption underwhelming. Billions spent with unclear returns. The skeptics have a point — on the surface.

But they're missing how technology adoption actually works. And they're fundamentally misunderstanding the competitive dynamics at play.

This essay argues three things:

1. Incumbents with fallback products have iteration runway that pure-play model companies don't
2. Enterprise AI value comes from orchestration and diffusion, not frontier model capability
3. The capex "problem" is actually a moat — and every drawdown is an opportunity

---

## The Fallback Moat: Why Iteration Runway Matters

Here's what the bubble narrative misses: **technology has always worked by hacking at it until it fits.**

Microsoft Copilot adoption is disappointing? They see why. The implementation isn't quite right. And all that will happen is they'll fix it, iterate, and try again. 

Why can they afford this patience? Because the fallback is something people are rigid about. Nobody's leaving Excel. Nobody's abandoning Teams. The failure mode isn't "users leave" — it's "users don't adopt the new feature yet."

We've seen this movie before.

**Skype → Zoom → Teams.** Microsoft "lost" video calling to Zoom during the pandemic. Then won it back through bundling, persistence, and iteration. The patience of incumbents is systematically underestimated.

**Google Search → ChatGPT / Perplexity → Gemini.** ChatGPT looked like an existential threat to Google's core business. Eighteen months later? Google's still processing 8.5 billion searches daily, AI Overviews are rolling out, and Gemini is integrated across the product suite. The default survived.

This is the pattern. Incumbents can afford to be wrong for years because their fallback product isn't going anywhere.

**Pure-play model companies don't have this luxury.**

OpenAI has ChatGPT — that's real distribution, 300M+ users. But it's consumer distribution, not enterprise lock-in. And the moment their model isn't best-in-class, the switching costs are minimal.

Apple demonstrated this perfectly: they moved from ChatGPT to Gemini without friction. So can Microsoft. So can anyone building on APIs.

Anthropic is even more exposed — primarily API and enterprise, no meaningful consumer lock-in. If Claude isn't the best model for a use case, why would an enterprise stay?

The financials make this stark. OpenAI generated $4.3 billion in revenue in the first half of 2025 but posted a $13.5 billion net loss. Microsoft's Q1 fiscal 2026 filing revealed OpenAI lost approximately $11.5 billion in a single quarter. Deutsche Bank estimates OpenAI will accumulate $143 billion in negative cash flow through 2029 — "no startup in history has operated with losses on anything approaching this scale." Microsoft, holding a 27% stake, absorbed a $3.1 billion hit to net income from OpenAI's losses last quarter. But here's the difference: Microsoft still posted $27.7 billion in net income. They can absorb this. OpenAI, without a fallback revenue stream, cannot afford a stumble. The dependency also cuts both ways — OpenAI has now committed to purchasing $250 billion in Azure services. Microsoft's downside is capped; their upside is a locked-in hyperscale customer regardless of who wins the model race.

The frontier gap between leading models has compressed to 3-5 months. That's not enough time to build a durable moat. Distribution wins. And MSFT, GOOG, and AMZN have distribution that took decades to build.

---

## A→B Works. A→C Doesn't (Yet). And That's Fine.

Here's a framework for understanding where AI is actually creating value:

**A→B: AI assists your existing workflow**
- Copilot autocompleting code
- LLM summarizing a document
- AI flagging suspicious transactions for human review

**A→C: AI replaces an entire workflow step autonomously**
- Fully autonomous customer support
- AI SDRs running sales outreach end-to-end
- Agentic systems making unsupervised decisions

The bubble narrative focuses on A→C not working. And they're right — it mostly doesn't. Yet.

But A→B is working brilliantly, at scale, right now.

**JPMorgan's LLM Suite** has 250,000 employees with access. Half use it daily. They're creating investment banking decks in 30 seconds that used to take junior analysts hours. Every eight weeks, the platform gets updated with more integrations. This is iterative value creation, not revolutionary disruption.

**HSBC's AI-powered AML system** detects 2-4x more suspicious activity than previous systems while reducing false positives by 60%. Detection time dropped from weeks to eight days. This is AI enhancing existing compliance workflows — not replacing compliance officers.

**Goldman Sachs' GS AI Assistant** handles document summarization, content drafting, data analysis, and translation. Model-agnostic design — they use GPT-4, Gemini, and Claude depending on the task. But critically: no client-facing AI yet. They're "moving very deliberately, very carefully" because of the regulated nature of financial services. Human in the loop, always.

**Deutsche Bank** reported 200+ AI use cases in production as of 2024, with LLMs generating millions of lines of code, credit reports, and audit memos. Their DB Lumina research assistant accelerates financial report creation from days to minutes.

The pattern across all successful enterprise deployments is identical:

1. **LLM does the task** (spreading financial data, drafting documents, detecting patterns)
2. **Validation layer checks outputs** against business rules and compliance requirements  
3. **Human reviews exceptions** and approves high-stakes decisions

This isn't a workaround for unreliable LLMs. It's the architecture that makes LLMs reliable.

Palantir's Alex Karp articulated this perfectly: *"Once you build a software layer to orchestrate and manage the LLMs in a language your enterprise understands, you actually can create value."*

Palantir's AIP approach embodies this. Their system doesn't ask LLMs to guess context from text — it passes structured ontology objects that already carry meaning, relationships, and constraints. The model doesn't need to hallucinate because it's reasoning over governed, connected data.

The value isn't in the model. It's in the orchestration layer.

---

## Enterprise Doesn't Need Frontier

The scaling laws conversation has created a misleading impression. Yes, the cost-per-improvement at the frontier is increasing. GPT-3 to GPT-4 was maybe 10x compute for 3x capability. GPT-4 to GPT-5 might be 10x compute for 1.3x capability.

But here's what matters: **enterprise doesn't need frontier improvements.**

Deutsche Bank is always two versions of Excel behind — not because they can't afford the latest, but because enterprise IT needs to vet before releasing. The same applies to AI models.

Current models are already good enough for most A→B use cases. The value unlock isn't advancement to new capabilities — it's **diffusion of current capabilities** across enterprise workflows.

The runway exists. But it's about deployment and orchestration, not raw model performance.

This reframe changes the investment thesis entirely. You're not betting on "will GPT-5 be transformative?" You're betting on "will enterprises continue integrating current-generation AI into workflows?" 

The answer, based on every data point from JPMorgan to Deutsche Bank to HSBC, is clearly yes.

---

## The Capex Question: Can They Sustain It?

Big Tech's combined 2025 capex is tracking above $400 billion. Microsoft alone is at $88 billion for fiscal 2025, growing to potentially $140 billion in fiscal 2026. Amazon guided to $125 billion for 2025, increasing in 2026.

The skeptic's question: can this continue?

The numbers say yes.

Even at these spending levels, the hyperscalers remain free cash flow positive. Google and Microsoft's free cash flow is actually *increasing* despite the capex surge. Consensus estimates suggest AI capex will climb to 94% of operating cash flows (minus dividends and buybacks) in 2025-2026 — aggressive, but still below 100%.

They don't need to borrow to fund this. But it's getting close.

More importantly: **what's the alternative?**

Amazon's CFO put it directly: "We'll continue to make significant investments, especially in AI... We believe it to be a massive opportunity with the potential for strong returns on invested capital over the long term." And notably, Amazon is doing this while simultaneously laying off 14,000-30,000 corporate employees — primarily in HR, middle management, and analytics. This isn't contradiction; it's confirmation. Jassy has been explicit: "We will need fewer people doing some of the jobs that are being done today." The efficiency gains from AI adoption are showing up as reduced headcount. The capex funds the infrastructure; the layoffs capture the value. That's not a bubble — that's ROI materialising.

The alternative to spending $125 billion on AI infrastructure is ceding the cloud and enterprise market to competitors. That's existential.

And adoption isn't linear — it's a step function.

JPMorgan went from zero to 200,000 LLM Suite users in eight months. Each integration layer unlocks the next wave of use cases. Deutsche Bank uploads data to Google Cloud in chunks; with each chunk, adoption steps up for the newly available inventory.

The capex creates capacity. The orchestration layers create demand. The step-function follows.

---

## The Cautions

This isn't a thesis without risks.

**Regional models and open source.** DeepSeek and other regionally-developed models keep pushing the boundaries of what's achievable at lower cost. Open-source alternatives create pricing pressure. For Amazon specifically, there's exposure if price-sensitive markets choose cheaper alternatives to AWS.

**Market patience.** Enterprise adoption moves slower than markets want. Sentiment can turn before the step-function becomes visible in reported numbers. If you're holding through a drawdown, you need conviction in the thesis.

**Meta is the outlier.** They're spending $70-72 billion in capex with no direct AI revenue line. Unlike Microsoft, Google, and Amazon, Meta doesn't have a cloud business to monetize AI directly. Their bet is that AI improves ad targeting — a real thesis, but less visible than "Azure AI revenue grew X%." 

But for Microsoft, Google, and Amazon? The thesis holds. Cloud revenue is growing. AI integration is accelerating. The fallback products aren't going anywhere.

---

## Conclusion

The "AI bubble" narrative conflates two different questions:

1. **Will AI spending generate returns?** — Yes, through orchestration, diffusion, and enterprise integration
2. **Will markets wait patiently for those returns?** — Unknown, but irrelevant if you have conviction

The incumbents have fallback moats. They have iteration runway. They have distribution that took decades to build. And they're generating free cash flow while investing at historic levels.

Models will keep improving — it's math, even if returns are diminishing at the frontier. Chips will keep helping. And the incumbents will keep hacking at it until it works.

The people calling this a bubble are watching the messy middle of technology adoption and mistaking it for failure. 

It isn't. It's just how technology has always worked.

---

*Disclaimer: This is analysis, not financial advice. Do your own research.*